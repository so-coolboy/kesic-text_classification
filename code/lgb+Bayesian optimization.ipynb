{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv',lineterminator='\\n')\n",
    "df_test = pd.read_csv('../input/test.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jo bhi ap se tou behtar hoon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ya Allah meri sister Affia ki madad farma</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Yeh khud chahta a is umar main shadi krna.  ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tc ? Apky mun xe exe alfax achy nae lgty ðŸ˜’ðŸ’ƒ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Good</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                             review  label\n",
       "0   1                       Jo bhi ap se tou behtar hoon      0\n",
       "1   2          ya Allah meri sister Affia ki madad farma      1\n",
       "2   3  Yeh khud chahta a is umar main shadi krna.  ha...      0\n",
       "3   4        Tc ? Apky mun xe exe alfax achy nae lgty ðŸ˜’ðŸ’ƒ      0\n",
       "4   5                                               Good      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'] = df_train['label'].map({'Negative':0,'Positive':1})\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(word):\n",
    "  word = re.sub(r'\\#\\.', '', word)\n",
    "  word = re.sub(r'\\n', '', word)\n",
    "  word = re.sub(r',', '', word)\n",
    "  word = re.sub(r'\\-', ' ', word)\n",
    "  word = re.sub(r'\\.', '', word)\n",
    "  word = re.sub(r'\\\\', ' ', word)\n",
    "  word = re.sub(r'\\\\x\\.+', '', word)\n",
    "  word = re.sub(r'\\d', '', word)\n",
    "  word = re.sub(r'^_.', '', word)\n",
    "  word = re.sub(r'_', ' ', word)\n",
    "  word = re.sub(r'^ ', '', word)\n",
    "  word = re.sub(r' $', '', word)\n",
    "  word = re.sub(r'\\?', '', word)\n",
    "  return word.lower() \n",
    "\n",
    "def array_cleaner(array):\n",
    "  # X = array\n",
    "  X = []\n",
    "  for sentence in array:\n",
    "    clean_sentence = ''\n",
    "    words = sentence.split(' ')\n",
    "    for word in words:\n",
    "      clean_sentence = clean_sentence +' '+ cleaner(word)\n",
    "    X.append(clean_sentence)\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6328\n",
      "2712\n",
      "6328\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['review']\n",
    "X_train = df_train['review']\n",
    "y_train = df_train['label']\n",
    "\n",
    "X_train = array_cleaner(X_train)\n",
    "X_test = array_cleaner(X_test)\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_train = y_train.astype('int8')\n",
    "y_train[:6]\n",
    "\n",
    "X_all = X_train + X_test # Combine both to fit the tokenizer.\n",
    "lentrain = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 2\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True,ngram_range=(1, ngram), max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X_all) # This is the slow part!\n",
    "X_all = vectorizer.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chuli = X_all[:lentrain] # Separate back into training and test sets. \n",
    "X_test_chuli = X_all[lentrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_CV(min_data_in_leaf,feature_fraction,bagging_fraction,):\n",
    "    \n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "    oof = np.zeros(X_train_chuli.shape[0])\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_chuli, y_train)):\n",
    "        print(\"fold nÂ°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(X_train_chuli[trn_idx],\n",
    "                               label=y_train[trn_idx],\n",
    "                               )\n",
    "        val_data = lgb.Dataset(X_train_chuli[val_idx],\n",
    "                               label=y_train[val_idx],\n",
    "                               )\n",
    "    \n",
    "        param = {\n",
    "            'max_depth': -1,\n",
    "            'min_data_in_leaf': int(min_data_in_leaf), \n",
    "            'objective':'binary',\n",
    "            'bagging_fraction':bagging_fraction,\n",
    "            'feature_fraction':feature_fraction,\n",
    "            'learning_rate': 0.005,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"bagging_freq\": 5,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"metric\": 'auc',\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "    \n",
    "        clf = lgb.train(param,\n",
    "                        trn_data,\n",
    "                        8000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 500)\n",
    "        \n",
    "        oof[val_idx] = clf.predict(X_train_chuli[val_idx],\n",
    "                                   num_iteration=clf.best_iteration)\n",
    "        \n",
    "        del clf, trn_idx, val_idx\n",
    "        \n",
    "    return metrics.roc_auc_score(y_train,oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_BO = BayesianOptimization(LGB_CV, {\n",
    "        'min_data_in_leaf': (2, 40),\n",
    "        'bagging_fraction': (0.01, 0.999),\n",
    "        'feature_fraction':(0.01, 0.999)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | min_da... |\n",
      "-------------------------------------------------------------\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.828078\tvalid_1's auc: 0.757608\n",
      "[1000]\ttraining's auc: 0.857157\tvalid_1's auc: 0.764559\n",
      "[1500]\ttraining's auc: 0.878674\tvalid_1's auc: 0.763058\n",
      "Early stopping, best iteration is:\n",
      "[1030]\ttraining's auc: 0.858527\tvalid_1's auc: 0.764781\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.832002\tvalid_1's auc: 0.746197\n",
      "[1000]\ttraining's auc: 0.859313\tvalid_1's auc: 0.74833\n",
      "Early stopping, best iteration is:\n",
      "[999]\ttraining's auc: 0.859298\tvalid_1's auc: 0.748365\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.830668\tvalid_1's auc: 0.724399\n",
      "[1000]\ttraining's auc: 0.859244\tvalid_1's auc: 0.736613\n",
      "[1500]\ttraining's auc: 0.880154\tvalid_1's auc: 0.737965\n",
      "[2000]\ttraining's auc: 0.897413\tvalid_1's auc: 0.737323\n",
      "Early stopping, best iteration is:\n",
      "[1609]\ttraining's auc: 0.884262\tvalid_1's auc: 0.738449\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.825812\tvalid_1's auc: 0.764108\n",
      "[1000]\ttraining's auc: 0.854537\tvalid_1's auc: 0.770223\n",
      "[1500]\ttraining's auc: 0.875523\tvalid_1's auc: 0.771366\n",
      "[2000]\ttraining's auc: 0.89272\tvalid_1's auc: 0.77036\n",
      "Early stopping, best iteration is:\n",
      "[1576]\ttraining's auc: 0.878071\tvalid_1's auc: 0.771963\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.828342\tvalid_1's auc: 0.761278\n",
      "[1000]\ttraining's auc: 0.85794\tvalid_1's auc: 0.76428\n",
      "[1500]\ttraining's auc: 0.879936\tvalid_1's auc: 0.764513\n",
      "Early stopping, best iteration is:\n",
      "[1489]\ttraining's auc: 0.879339\tvalid_1's auc: 0.764719\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 0.6895  \u001b[0m | \u001b[0m 0.4132  \u001b[0m | \u001b[0m 28.56   \u001b[0m |\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.845379\tvalid_1's auc: 0.774218\n",
      "[1000]\ttraining's auc: 0.879139\tvalid_1's auc: 0.778252\n",
      "Early stopping, best iteration is:\n",
      "[894]\ttraining's auc: 0.873848\tvalid_1's auc: 0.778779\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.846152\tvalid_1's auc: 0.761879\n",
      "[1000]\ttraining's auc: 0.881811\tvalid_1's auc: 0.76642\n",
      "Early stopping, best iteration is:\n",
      "[777]\ttraining's auc: 0.86912\tvalid_1's auc: 0.766824\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.847858\tvalid_1's auc: 0.740955\n",
      "[1000]\ttraining's auc: 0.882288\tvalid_1's auc: 0.758636\n",
      "[1500]\ttraining's auc: 0.903737\tvalid_1's auc: 0.76173\n",
      "[2000]\ttraining's auc: 0.919273\tvalid_1's auc: 0.762335\n",
      "Early stopping, best iteration is:\n",
      "[1906]\ttraining's auc: 0.916669\tvalid_1's auc: 0.763174\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.839609\tvalid_1's auc: 0.782628\n",
      "[1000]\ttraining's auc: 0.875985\tvalid_1's auc: 0.792725\n",
      "[1500]\ttraining's auc: 0.898919\tvalid_1's auc: 0.791968\n",
      "Early stopping, best iteration is:\n",
      "[1139]\ttraining's auc: 0.883157\tvalid_1's auc: 0.793355\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.844395\tvalid_1's auc: 0.772184\n",
      "[1000]\ttraining's auc: 0.879269\tvalid_1's auc: 0.78111\n",
      "[1500]\ttraining's auc: 0.901567\tvalid_1's auc: 0.781414\n",
      "Early stopping, best iteration is:\n",
      "[1320]\ttraining's auc: 0.894141\tvalid_1's auc: 0.782145\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.7754  \u001b[0m | \u001b[95m 0.9774  \u001b[0m | \u001b[95m 0.7297  \u001b[0m | \u001b[95m 25.68   \u001b[0m |\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.643033\tvalid_1's auc: 0.622391\n",
      "[1000]\ttraining's auc: 0.678715\tvalid_1's auc: 0.647497\n",
      "[1500]\ttraining's auc: 0.684155\tvalid_1's auc: 0.654545\n",
      "Early stopping, best iteration is:\n",
      "[1300]\ttraining's auc: 0.68835\tvalid_1's auc: 0.656381\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.617303\tvalid_1's auc: 0.581639\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.596869\tvalid_1's auc: 0.605002\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.645938\tvalid_1's auc: 0.592247\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's auc: 0.646216\tvalid_1's auc: 0.622822\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.637086\tvalid_1's auc: 0.610431\n",
      "[1000]\ttraining's auc: 0.649557\tvalid_1's auc: 0.614705\n",
      "[1500]\ttraining's auc: 0.671657\tvalid_1's auc: 0.640235\n",
      "[2000]\ttraining's auc: 0.686025\tvalid_1's auc: 0.652431\n",
      "[2500]\ttraining's auc: 0.692168\tvalid_1's auc: 0.653515\n",
      "Early stopping, best iteration is:\n",
      "[2189]\ttraining's auc: 0.690231\tvalid_1's auc: 0.662101\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.622389\tvalid_1's auc: 0.613961\n",
      "[1000]\ttraining's auc: 0.648771\tvalid_1's auc: 0.64329\n",
      "[1500]\ttraining's auc: 0.666094\tvalid_1's auc: 0.658276\n",
      "[2000]\ttraining's auc: 0.680914\tvalid_1's auc: 0.678215\n",
      "[2500]\ttraining's auc: 0.689197\tvalid_1's auc: 0.683429\n",
      "[3000]\ttraining's auc: 0.696042\tvalid_1's auc: 0.692411\n",
      "[3500]\ttraining's auc: 0.695666\tvalid_1's auc: 0.689577\n",
      "Early stopping, best iteration is:\n",
      "[3232]\ttraining's auc: 0.699437\tvalid_1's auc: 0.697986\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6274  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's auc: 0.5\tvalid_1's auc: 0.5\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.485   \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 17.85   \u001b[0m |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "LGB_BO.maximize(init_points=2,n_iter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold nÂ°0\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.861537\tvalid_1's auc: 0.782503\n",
      "[1000]\ttraining's auc: 0.901224\tvalid_1's auc: 0.785904\n",
      "[1500]\ttraining's auc: 0.923954\tvalid_1's auc: 0.784351\n",
      "Early stopping, best iteration is:\n",
      "[1175]\ttraining's auc: 0.910107\tvalid_1's auc: 0.786667\n",
      "fold nÂ°1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.861512\tvalid_1's auc: 0.779871\n",
      "[1000]\ttraining's auc: 0.901472\tvalid_1's auc: 0.787653\n",
      "[1500]\ttraining's auc: 0.925797\tvalid_1's auc: 0.788059\n",
      "Early stopping, best iteration is:\n",
      "[1494]\ttraining's auc: 0.925569\tvalid_1's auc: 0.788155\n",
      "fold nÂ°2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.864899\tvalid_1's auc: 0.757766\n",
      "[1000]\ttraining's auc: 0.90292\tvalid_1's auc: 0.77437\n",
      "[1500]\ttraining's auc: 0.92591\tvalid_1's auc: 0.777918\n",
      "[2000]\ttraining's auc: 0.941596\tvalid_1's auc: 0.780061\n",
      "[2500]\ttraining's auc: 0.953297\tvalid_1's auc: 0.781995\n",
      "[3000]\ttraining's auc: 0.961737\tvalid_1's auc: 0.782365\n",
      "[3500]\ttraining's auc: 0.968292\tvalid_1's auc: 0.781863\n",
      "Early stopping, best iteration is:\n",
      "[3306]\ttraining's auc: 0.965912\tvalid_1's auc: 0.782821\n",
      "fold nÂ°3\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.857592\tvalid_1's auc: 0.796319\n",
      "[1000]\ttraining's auc: 0.897655\tvalid_1's auc: 0.811844\n",
      "[1500]\ttraining's auc: 0.921587\tvalid_1's auc: 0.814631\n",
      "[2000]\ttraining's auc: 0.938075\tvalid_1's auc: 0.815501\n",
      "[2500]\ttraining's auc: 0.949806\tvalid_1's auc: 0.815348\n",
      "Early stopping, best iteration is:\n",
      "[2472]\ttraining's auc: 0.949225\tvalid_1's auc: 0.815592\n",
      "fold nÂ°4\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[500]\ttraining's auc: 0.862303\tvalid_1's auc: 0.785002\n",
      "[1000]\ttraining's auc: 0.903095\tvalid_1's auc: 0.795086\n",
      "[1500]\ttraining's auc: 0.92666\tvalid_1's auc: 0.797655\n",
      "[2000]\ttraining's auc: 0.942242\tvalid_1's auc: 0.798978\n",
      "[2500]\ttraining's auc: 0.953667\tvalid_1's auc: 0.79913\n",
      "Early stopping, best iteration is:\n",
      "[2359]\ttraining's auc: 0.9506\tvalid_1's auc: 0.799523\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "oof = np.zeros(X_train_chuli.shape[0])\n",
    "predictions = np.zeros(X_test_chuli.shape[0])\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train_chuli, y_train)):\n",
    "    print(\"fold nÂ°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(X_train_chuli[trn_idx],\n",
    "                           label=y_train[trn_idx],\n",
    "                           )\n",
    "    val_data = lgb.Dataset(X_train_chuli[val_idx],\n",
    "                           label=y_train[val_idx],\n",
    "                           )\n",
    "\n",
    "    param = {\n",
    "        'max_depth': -1,\n",
    "        'min_data_in_leaf': 16, \n",
    "        'objective':'binary',\n",
    "        'bagging_fraction':0.999,\n",
    "        'feature_fraction':0.999,\n",
    "        'learning_rate': 0.005,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"bagging_freq\": 5,\n",
    "        \"bagging_seed\": 11,\n",
    "        \"metric\": 'auc',\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    8000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 500)\n",
    "\n",
    "    oof[val_idx] = clf.predict(X_train_chuli[val_idx],\n",
    "                               num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(X_test_chuli, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.42070474, 0.6040751 , 0.97468436, 0.71787887])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "predictions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_output = pd.DataFrame({\"ID\":df_test[\"ID\"], \"Pred\":predictions})\n",
    "lgb_output.to_csv('lgb_new.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
